import os

import requests
from bs4 import BeautifulSoup
from urllib.parse import urlparse, urljoin
import ebooklib
from ebooklib import epub

def scrape_chapter(session, url, headers):
    response = session.get(url, headers=headers)
    response.raise_for_status()
    soup = BeautifulSoup(response.text, 'html.parser')
    chapter_text = ""
    for tag in soup.select('.entry-content'):
        chapter_text += str(tag)
    return chapter_text

def main():
    try:
        # Initialize EPUB book
        book = epub.EpubBook()
        book.set_identifier('id123456')
        book.set_language('en')
        book.add_author("ari")

        headers = {'User-Agent': 'Mozilla/5.0'}
        session = requests.Session()

        url = input("Enter the URL to scrape: ")
        start_chapter = int(input("Enter the starting chapter: ")) - 1  # Subtracting 1 to make it zero-based
        chapters_to_scrape = int(input("Enter the number of chapters to scrape: "))

        print(f'Fetching data from URL: {url}')

        response = session.get(url, headers=headers)
        response.raise_for_status()
        
        soup = BeautifulSoup(response.text, 'html.parser')
        base_url = urlparse(url).scheme + "://" + urlparse(url).netloc

        # Scrape title and image
        title = soup.select_one('.book-info h1').text.strip()
        img_url = soup.select_one('.book-img img')['src']
        img_response = session.get(img_url, headers=headers)
        
        # Add title and cover image to the EPUB
        book.set_title(title)
        book.set_cover("image.jpg", img_response.content)

        c1 = epub.EpubHtml(title='Introduction', file_name='intro.xhtml', lang='en')
        c1.content = '''
        <h1>Introduction</h1>
        <p>This book was programmatically generated by Ari. The content you will read in the following chapters has been scraped from various online sources and compiled into an EPUB format for easier reading and accessibility.</p>
        <p>The idea behind this automation is to make a wide array of information readily available in a format that can be conveniently consumed. Each chapter in this book corresponds to different web pages or articles from the source URL provided.</p>
        <p>We hope you find this compilation informative and enjoyable!</p>
        '''
        book.add_item(c1)

        chapter_links = []
        for index, element in enumerate(soup.select('#morelist li a')[start_chapter:start_chapter+chapters_to_scrape]):
            relative_link = element['href']
            absolute_link = urljoin(base_url, relative_link)
            chapter_links.append(absolute_link)

        webTitle = soup.find('title').text

        chapter_items = [c1]

        for i, chapter_url in enumerate(chapter_links):
            print(f'Fetching data from chapter URL: {chapter_url}')
            chapter_text = scrape_chapter(session, chapter_url, headers)
            chapter_title = f'Chapter {start_chapter + i + 1}'
            chapter_item = epub.EpubHtml(title=chapter_title, file_name=f'chap_{start_chapter + i + 1}.xhtml', lang='en')
            chapter_item.content = f'<h1>{chapter_title}</h1>{chapter_text}'
            book.add_item(chapter_item)
            chapter_items.append(chapter_item)

        book.toc = chapter_items
        book.add_item(epub.EpubNcx())
        book.add_item(epub.EpubNav())
        book.spine = ['nav'] + chapter_items

        # Create the "books" folder if it doesn't exist
        if not os.path.exists('books'):
            os.makedirs('books')

        # Save the EPUB in the "books" folder
        epub.write_epub(os.path.join('books', f'{title}.epub'), book, {})

        print(f"Scraped data and generated EPUB for {title}")

    except Exception as e:
        print(f'An error occurred: {e}')

if __name__ == '__main__':
    main()
