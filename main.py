import os
import requests
from bs4 import BeautifulSoup
from urllib.parse import urljoin
from ebooklib import epub


def initialize_epub(title, author):
    book = epub.EpubBook()
    book.set_identifier('id123456')
    book.set_language('en')
    book.set_title(title)
    book.add_author(author)
    return book


def fetch_url(session, url, headers):
    response = session.get(url, headers=headers)
    response.raise_for_status()
    return BeautifulSoup(response.text, 'html.parser')


def search_novelhall(session, query, headers):
    search_url = f"https://www.novelhall.com/index.php?s=so&module=book&keyword={query}"
    search_soup = fetch_url(session, search_url, headers)

    search_results = []
    for row in search_soup.select('.section3 table tbody tr'):
        title = row.select_one('td:nth-child(2) a').text.strip()
        href = row.select_one('td:nth-child(2) a')['href']
        search_results.append((title, href))

    return search_results


def scrape_novelhall(session, url, headers, start_chapter, chapters_to_scrape):
    soup = fetch_url(session, url, headers)
    title = soup.select_one('.book-info h1').text.strip()
    img_url = soup.select_one('.book-img img')['src']
    img_response = session.get(img_url, headers=headers)

    chapter_links = [urljoin(url, elem['href']) for elem in soup.select(
        '#morelist li a')[start_chapter:start_chapter + chapters_to_scrape]]
    chapters = []
    for chapter_url in chapter_links:
        chapter_soup = fetch_url(session, chapter_url, headers)
        chapter_text = "".join(str(tag)
                               for tag in chapter_soup.select('.entry-content'))
        chapters.append(chapter_text)

    return title, img_response.content, chapters


def get_intro():
    c1 = epub.EpubHtml(title='Introduction',
                       file_name='intro.xhtml', lang='en')
    c1.content = '''
    <h1>Introduction</h1>
    <p>This book was programmatically generated by Ari. The content you will read in the following chapters has been scraped from various online sources and compiled into an EPUB format for easier reading and accessibility.</p>
    <p>The idea behind this automation is to make a wide array of information readily available in a format that can be conveniently consumed. Each chapter in this book corresponds to different web pages or articles from the source URL provided.</p>
    <p>We hope you find this compilation informative and enjoyable!</p>
    '''
    return c1


def save_epub(book, title):
    if not os.path.exists('books'):
        os.makedirs('books')
    epub.write_epub(os.path.join('books', f'{title}.epub'), book, {})


def main():
    try:
        headers = {'User-Agent': 'Mozilla/5.0'}
        session = requests.Session()

        query = input("Enter the book title to search: ")
        search_results = search_novelhall(session, query, headers)

        if not search_results:
            print("No results found.")
            return

        print("Search Results:")
        for i, (title, _) in enumerate(search_results):
            print(f"{i+1}. {title}")

        choice = int(input("Select a book to scrape (enter the number): "))
        if choice < 1 or choice > len(search_results):
            print("Invalid choice.")
            return

        _, relative_url = search_results[choice - 1]
        base_url = "https://www.novelhall.com"
        url = urljoin(base_url, relative_url)

        start_chapter = int(input("Enter the starting chapter: ")) - 1
        chapters_to_scrape = int(
            input("Enter the number of chapters to scrape: "))

        title, cover_image, chapters = scrape_novelhall(
            session, url, headers, start_chapter, chapters_to_scrape)

        book = initialize_epub(title, "Ari")
        book.set_cover("image.jpg", cover_image)

        intro = get_intro()
        book.add_item(intro)

        chapter_items = [intro]

        for i, chapter_text in enumerate(chapters):
            chapter_title = f'Chapter {start_chapter + i + 1}'
            chapter_item = epub.EpubHtml(
                title=chapter_title, file_name=f'chap_{start_chapter + i + 1}.xhtml', lang='en')
            chapter_item.content = f'<h1>{chapter_title}</h1>{chapter_text}'
            book.add_item(chapter_item)
            chapter_items.append(chapter_item)

        book.toc = chapter_items
        book.add_item(epub.EpubNcx())
        book.add_item(epub.EpubNav())
        book.spine = ['nav'] + chapter_items

        save_epub(book, title)

        print(f"Scraped data and generated EPUB for {title}")

    except Exception as e:
        print(f'An error occurred: {e}')


if __name__ == '__main__':
    main()
